from typing import Type
from pydantic import BaseModel
import instructor
from cognee.infrastructure.llm.llm_interface import LLMInterface
from cognee.infrastructure.llm.config import get_llm_config
from openai import OpenAI
import httpx
import json
import re
import litellm
from litellm import completion
from typing import List, Dict, Any


class OllamaAPIAdapter(LLMInterface):
    """Adapter for a Generic API LLM provider using instructor with an OpenAI backend."""

    def __init__(self, endpoint: str, api_key: str, model: str, name: str, max_tokens: int):
        self.name = name
        self.model = model
        self.api_key = api_key
        self.endpoint = endpoint
        self.max_tokens = max_tokens



    async def acreate_structured_output(
        self, text_input: str, system_prompt: str, response_model: Type[BaseModel]
    ) -> BaseModel:
        print("!!!!!!!!!!!=====Call actreate_structured_output======!!!!!!!")

        # 让 `instructor` 适配 `litellm`
        class LitellmWrapper:
            def __init__(self, model: str, api_base: str, format:str):
                self.model = model
                self.api_base = api_base
                self.format = format

            def completion(self, messages: List[Dict[str, Any]], **kwargs):
                if self.format == "str":
                    return litellm.completion(
                        model=self.model,
                        api_base=self.api_base,
                        messages=messages 
                    )
                else:
                    return litellm.completion(
                        model=self.model,
                        api_base=self.api_base,
                        messages=messages,
                        format="json"
                    )

        def extract_response(response, schema):
            # 尝试从 schema 中提取所有需要匹配的键
            properties = schema.get("properties", {}) if isinstance(schema, dict) else {}
            keys = list(properties.keys())

            if not keys:
                print("无法从 schema 中提取键，使用默认正则表达式")
                pattern = r'\{[^{}]*\}'
            else:
                # 为每个键构造匹配模式，假定值为双引号括起来的字符串（可根据实际情况调整）
                key_patterns = [rf'"{key}"\s*:\s*".+?"' for key in keys]
                # 允许各项之间出现任意内容（非贪婪模式），构造最终模式
                pattern = r'\{' + r'.*?'.join(key_patterns) + r'\}'
                print("动态生成的正则表达式:", pattern)

            matches = re.findall(pattern, response, re.DOTALL)
            if matches:
                for json_str in matches:
                    try:
                        data = json.loads(json_str)
                        print("提取到的 JSON 数据：", data)
                    except json.JSONDecodeError as e:
                        print("JSON解码错误:", e)
            else:
                print("未匹配到符合条件的 JSON 子串")

            return matches
    
        if issubclass(response_model, BaseModel):
            schema = response_model.model_json_schema()
            print("======schema:", schema)
        else:
            schema = "str"
            print("======schema:", schema)

        # ✅ 创建 `litellm` 代理
        llm_adapter = LitellmWrapper(model="ollama/qwq", api_base="http://localhost:11434", format=schema)

        client = instructor.from_litellm(completion)

        response = client.chat.completions.create(
            model = "ollama/qwq",
            messages=[
                {
                    "role": "user",
                    "content": text_input
                }
            ],
            response_model = response_model
        )

        print("======response:", response)

        '''
        if schema=="str":
            response = completion(
                model="ollama/qwq",
                messages=[
                    {
                        "role": "user",
                        "content": "respond in json, what's the weather"
                    },
                    { 
                        "role": "system", 
                        "content": "You must output a valid JSON object that exactly matches the schema below, and output NOTHING else. "
                        "Do not include any chain-of-thought or extra explanation. The JSON object must not contain any extra keys.\n"
                        "Schema: {\"id\": \"string\", \"name\": \"string\", \"location\": \"string\"}"
                        "Do not include any extra text, explanations, or tags such as <think>"
                    },
                ],
                api_base="http://localhost:11434",
                response_format={
                    "type": "json_schema",
                    "json_schema": {
                        "schema": {
                            "type": "object",
                            "properties": {
                                "id": {"type": "string"},
                                "name": {"type": "string"},
                                "location": {"type": "string"}
                            },
                            "required": ["id", "name", "location"]
                        }
                    }
                },
                stream = False
            )
        else:
            print("======！！！！Do else ！！！！！！+++++:")
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "schema": schema
                }
            }
            print("======response_format:", response_format)
            
            response = completion(
                model="ollama/qwq",
                messages=[
                    {
                        "role": "user",
                        "content": text_input
                    },
                    { 
                        "role": "system", 
                        "content": "You must output a valid JSON object that exactly matches the schema below, and output NOTHING else. "
                        "Do not include any chain-of-thought or extra explanation. The JSON object must not contain any extra keys.\n"
                        f"Schema: {schema}"
                        "Do not include any extra text, explanations, or tags such as <think>"
                    },
                ],
                api_base="http://localhost:11434",
                response_format=response_format,
                stream = False
            )
            
        
        response_str = response.json()
        content = response_str["choices"][0]["message"]["content"]
        print("++++++++++content+++++++++:",content)
        response = extract_response(content, schema)
        print("!!!!!!!!!Debug=========:",response)
        return response'
        '''
